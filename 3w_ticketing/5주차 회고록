사용 언어 : Java 17
사용 프레임 : Spring Boot 3.3.1
작업 기간 : 6월 30일 ~ 7월 19일(3 ~ 5주차)

주제 : 콘서트 대기열 구현하기
- redis 사용 없이 순수 자바 코드 + 디비로 구현

주요 기능
- 콘서트 예매 시 대기열로 관리
- 날짜 / 좌석 조회
- 예매
- 포인트 조회/충전
- 결제

3주차
- 마일스톤 작성, 요구 분석, 시퀀스 다이어그램, ERD 설계, API 명세서 작성

4주차
- api 스웨거 작성, 주요 api 완성(useCase별 통합테스트 작성)

5주차
- Filter, Interceptor, 예외처리, 로깅 등 유효한 부가로직 구현, 서비스 정상구동되도록 완성, 회고록 작성

느낀점
하나의 주제로 진행한 과제이지만 매주 새로웠다.

3주차에는 직접 작성해 볼 일이 없던 마일스톤, 시퀀스 다이어그램, API 명세서 작성을 해보았고, 
문서 작성이라고 얕봤던 내 자신을 후회하며 밤을 지새워 과제를 제출했다.
과제 요건 중에 기본적으로 폴링으로 대기열을 확인한다고 가정한다, 라는 문구가 있었는데,
이게 정말 무슨 소리인지 알 수가 없었다.
폴링은 클라이언트에서 서버로 요청을 보내는 거고, 대기열은 큐로 구현해야 할 것 같은데,
두 개를 어떻게 연관지어서 사용하는 거지?
조원들도 다들 물음표라 멘토링 시간에 이것에 대한 설명만 한 시간을 들었다.
돌이켜 생각해봤을 때 너무 어렵게 생각했던 거였다.
대기열은 그냥 DB로 구현하면 되는 것이었고, 
폴링은 그 대기열을 확인하기 위한 api를 보내는 역할로 배정하는 개념일 뿐 직접 구현해야 하는 대상은 아니었다.

난이도 : ★★★☆☆
잘한 점 : 마일스톤 작성, 대기열 개념 이해
부족한 점 : 요구사항 분석



4주차에는 두 가지 주요 꼭지가 있었는데, 하나는 API 스웨거 작성, 다른 하나는 주요 api 완성이었다.
가끔 쓸데없는 거에 집착할 때가 있는데, 이번 주차에는 API 스웨거 작성에 꽂혔다.
API 스웨거 역시 처음 작성해보는 것이었고, 
설정이나 코드 상에 어디까지 어노테이션을 붙이고 기술하느냐에 따라 API 스웨거 페이지가 달리 만들어지는 것이 좀 신기했다.
덕분에 API 스웨거에 시간을 쏟아서 주요 api 완성하느라 이틀 밤을 지새웠다.
파사드도 4주차에 처음 적용해 본 개념이다. (솔직해 매주 처음하는 것들 뿐이다)
비즈니스 로직을 갖는 도메인과 그 도메인을 가져다 조립하는 파사드. 
그 직전에 다른 개발자 분이 중세의 성과 현대의 도시로 비유해서 설명해주셨어서 재밌는 개념으로 느껴졌다.
하지만 도메인과 파사드 모두 비즈니스 로직을 다루고 있었기 때문에, 
어느 영역에 어디까지 구현해야 하는지도 잘 모른채 막 구현했다.
3주차까지도 헤매었던 요구분석에 대해서는 조오금 감이 잡힌 것 같다.
파생 서비스 같은 곁가지는 최대한 쳐내고 오로지 핵심 기능에 집중해보려 노력했고,
코치님이 알려주신 대로 이 로직에서 어떤 게 발생하면 안되는지, 에러에 대해 많이 검증(?)하려고 노력했다.
요구분석은... 정말 많이 해볼 수 밖에 없는 것 같다고 느꼈다.

난이도 : ★★★★★
잘한 점 : API 스웨거 작성, 요구사항 분석
부족한 점 : TDD!
테스트 코드를 먼저 작성하고 비즈니스 로직을 작성하고...는 하겠는데,
조그마한 에러가 하나 날 때마다 테스트 코드도 고치고 비즈니스 로직도 고치려니 여간 번거로운 게 아니다.
아니, 너무 힘들다ㅠ



5주차에는 프로젝트의 완성도를 높이는 작업을 했다.
멘토링을 통해 도메인과 파사드를 어떻게 가져가야 할지 개념이 조금 잡혔고,
그를 토대로 리팩토링을 진행했다.
도메인의 비즈니스 로직을 작은 단위로 가져가되 너무 자잘해지지 않게 구현하고자 했고,
파사드에는 딱 조립의 역할만을 부여했다.
infrastructure도 분리하고 잘못 했던 통합테스트도 다시 했다.
그 후에 로깅을 추가했는데, response와 request 로깅을 필터로 해봤고,
그 외 로깅은 slf4j를 통해 컨트롤러, 파사드, 커스텀쿼리가 있는 레파지토리에 추가하였다.
response와 request 로깅을 필터로 한 이유는 클라이언트에게 직접 주고받는 데이터는 스프링의 간섭이 있기 전 순수 그 상태로 찍는 것이 좋다고 하여서!
아무래도 눈에 보이는 데이터다 보니 원본 그 자체가 중요한 것이라고 이해했다.
그 외 로그를 찍는 것이 도움이 된다고 생각된 곳에 로깅 로직을 작성했으며, 파사드와 도메인 같은 경우에는 파사드에 작성 후 도메인에도 작성 하면 중복으로 로깅을 하는 거라 판단해 비즈니스 로직 흐름을 보여주는 파사드에 로깅을 작성했다.
주요 로직마다 들어가는 토큰 유효성 검증을 intercepter로 분리했다.
사용자 검증하는 로직도 intercepter로 분리하고 싶었는데 시간이 없어서 미처 하지 못했다. 주말에 리팩토링 예정

난이도 : ★★☆☆☆
잘한 점 : 리팩토링
가장 많은 시간을 쏟은 만큼 나름 잘 분리한 것 같다.
부족한 점 : 로깅
필요한 부분에 찍는다고 찍었는데, 너무 많이 한 것 같기도 하다;;
다른 개발자분들은 어떻게 했는지 공부할 필요가 있다.


